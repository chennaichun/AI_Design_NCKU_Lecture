{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. OPEN DATA\n",
    "#### 2. API\n",
    "#### 3. WEB-SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. OPEN DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 直接下載公開資料\n",
    "\n",
    "\n",
    "政府公開資料\n",
    "https://data.gov.tw/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "台北公開資料\n",
    "\n",
    "http://data.taipei/opendata/datalist/datasetByFormat?oid=JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新竹市政府公開資料\n",
    "\n",
    "http://opendata.hccg.gov.tw/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://sheethub.com/data.taipei.gov.tw/%E8%87%BA%E5%8C%97%E5%B8%82%E4%BC%81%E6%A5%AD%E7%87%9F%E9%81%8B%E7%B8%BD%E9%83%A8%E5%88%86%E5%B8%83%E5%9C%96?page=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "應用程式介面（英語：Application Programming Interface，簡稱：API），\n",
    "又稱為應用編程介面，就是軟體系統不同組成部分銜接的約定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter API \n",
    "\n",
    "An Overview of the Twitter API\n",
    "There are many APIs on the Twitter platform that software developers can engage with, with the ultimate possibility to create fully automated systems which will interact with Twitter. While this feature could benefit companies by drawing insights from Twitter data, it's also suitable for smaller-scale projects, research, and fun. Here are a few of the most notable APIs provided by Twitter:\n",
    "\n",
    "Tweets: searching, posting, filtering, engagement, streaming etc.\n",
    "Ads: campaign and audience management, analytics.\n",
    "Direct messages (still in Beta): sending and receiving, direct replies, welcome messages etc.\n",
    "Accounts and users (Beta): account management, user interactions.\n",
    "Media: uploading and accessing photos, videos and animated GIFs.\n",
    "Trends: trending topics in a given location.\n",
    "Geo: information about known places or places near a location.\n",
    "There are many more possibilities with the Twitter APIs, which are not included in this list. Twitter is also constantly expanding its range of services by adding new APIs from time to time, and updating existing ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=wlnx-7cm4Gg&list=PL5tcWHG-UPH2zBfOz40HSzcGUPAVOOnu1&index=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developer.twitter.com/en/docs/basics/authentication/guides/access-tokens.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "consumer_key=\"consumer_key\"\n",
    "consumer_secret=\"consumer_secret\"\n",
    "access_token=\"access_token\"\n",
    "access_token_secret=\"access_token_secret\"\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    " \n",
    "# # # # TWITTER STREAMER # # # #\n",
    "class TwitterStreamer():\n",
    "    \"\"\"\n",
    "    Class for streaming and processing live tweets.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def stream_tweets(self, fetched_tweets_filename, hash_tag_list):\n",
    "        # This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "        listener = StdOutListener(fetched_tweets_filename)\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        stream = Stream(auth, listener)\n",
    "\n",
    "        # This line filter Twitter Streams to capture data by the keywords: \n",
    "        stream.filter(track=hash_tag_list)\n",
    "\n",
    "\n",
    "# # # # TWITTER STREAM LISTENER # # # #\n",
    "class StdOutListener(StreamListener):\n",
    "    \"\"\"\n",
    "    This is a basic listener that just prints received tweets to stdout.\n",
    "    \"\"\"\n",
    "    def __init__(self, fetched_tweets_filename):\n",
    "        self.fetched_tweets_filename = fetched_tweets_filename\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            print(data)\n",
    "            with open(self.fetched_tweets_filename, 'a') as tf:\n",
    "                tf.write(data)\n",
    "            return True\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data %s\" % str(e))\n",
    "        return True\n",
    "          \n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    " \n",
    "if __name__ == '__main__':\n",
    " \n",
    "    # Authenticate using config.py and connect to Twitter Streaming API.\n",
    "    hash_tag_list = [\"Boston\"]\n",
    "    fetched_tweets_filename = \"tweets.txt\"\n",
    "\n",
    "    twitter_streamer = TwitterStreamer()\n",
    "    twitter_streamer.stream_tweets(fetched_tweets_filename, hash_tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "data = []\n",
    "with codecs.open('tweets.txt','rU','utf-8') as f:\n",
    "    for line in f:\n",
    "       data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0][u'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[1][u'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[2][u'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0][\"user\"][u'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[4][\"user\"][u'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "data = []\n",
    "with codecs.open('tweets.txt','r') as f:\n",
    "    for line in f:\n",
    "       data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=[]\n",
    "description=[]\n",
    "for i in range(len(data)):\n",
    "    description.append(data[i][\"user\"][u'description'])\n",
    "    tweets.append(data[i][u'text'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tweets[0].encode('ascii', 'ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "datas={'tweet':tweets,'descrption':description}\n",
    "df=pd.DataFrame(datas)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def analyze_sentiment(tweet):\n",
    "    tweet=clean_tweet(tweet)\n",
    "    analysis = TextBlob(tweet)\n",
    "        \n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return \"positive\"\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return \"neutrality\"\n",
    "    else:\n",
    "        return \"negative\"\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "sentiment=np.array([analyze_sentiment(tweet) for tweet in tweets])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"]=sentiment\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "po=df[df[\"sentiment\"]==\"positive\"].count()\n",
    "nu=df[df[\"sentiment\"]==\"neutrality\"].count()\n",
    "na=df[df[\"sentiment\"]==\"negative\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dictionary = plt.figure()\n",
    "\n",
    "D = {u'positive':po.sentiment, u'neutrality': nu.sentiment, u'negative':na.sentiment}\n",
    "\n",
    "plt.bar(range(len(D)), D.values(), align='center')\n",
    "plt.xticks(range(len(D)), D.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url=\"http://search.twitter.com/search.json?q=china\"\n",
    "result=requests.get(url)\n",
    "better_result=result.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api= tweepy.API(auth)\n",
    "search_results = api.search(q=\"Tainan\", count=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "{\n",
    "    \"created_at\": \"Thu Jul 28 00:08:39 +0000 2016\",\n",
    "    \"in_reply_to_status_id\": null,\n",
    "    \"id_str\": \"758454081656467456\",\n",
    "    \"retweeted\": false,\n",
    "    \"entities\": {\n",
    "        \"hashtags\": [\n",
    "            {\n",
    "                \"text\": \"30secLL_bot\",\n",
    "                \"indices\": [\n",
    "                    25,\n",
    "                    37\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"urls\": [],\n",
    "        \"symbols\": [],\n",
    "        \"media\": [\n",
    "            {\n",
    "                \"url\": \"https://t.co/oQjf1qKsDC\",\n",
    "                \"id_str\": \"680158074653442048\",\n",
    "                \"source_status_id\": 680158389477875700,\n",
    "                \"source_user_id\": 4017736032,\n",
    "                \"source_user_id_str\": \"4017736032\",\n",
    "                \"media_url_https\": \"https://pbs.twimg.com/ext_tw_video_thumb/680158074653442048/pu/img/UkJ-B_AqbC_vEOcY.jpg\",\n",
    "                \"source_status_id_str\": \"680158389477875712\",\n",
    "                \"sizes\": {\n",
    "                    \"medium\": {\n",
    "                        \"w\": 600,\n",
    "                        \"h\": 338,\n",
    "                        \"resize\": \"fit\"\n",
    "                    },\n",
    "                    \"small\": {\n",
    "                        \"w\": 340,\n",
    "                        \"h\": 191,\n",
    "                        \"resize\": \"fit\"\n",
    "                    },\n",
    "                    \"thumb\": {\n",
    "                        \"w\": 150,\n",
    "                        \"h\": 150,\n",
    "                        \"resize\": \"crop\"\n",
    "                    },\n",
    "                    \"large\": {\n",
    "                        \"w\": 1024,\n",
    "                        \"h\": 576,\n",
    "                        \"resize\": \"fit\"\n",
    "                    }\n",
    "                },\n",
    "                \"display_url\": \"pic.twitter.com/oQjf1qKsDC\",\n",
    "                \"type\": \"photo\",\n",
    "                \"id\": 680158074653442000,\n",
    "                \"indices\": [\n",
    "                    38,\n",
    "                    61\n",
    "                ],\n",
    "                \"expanded_url\": \"http://twitter.com/30seclovelive/status/680158389477875712/video/1\",\n",
    "                \"media_url\": \"http://pbs.twimg.com/ext_tw_video_thumb/680158074653442048/pu/img/UkJ-B_AqbC_vEOcY.jpg\"\n",
    "            }\n",
    "        ],\n",
    "        \"user_mentions\": []\n",
    "    },\n",
    "    \"possibly_sensitive\": false,\n",
    "    \"in_reply_to_user_id_str\": null,\n",
    "    \"coordinates\": null,\n",
    "    \"retweet_count\": 153,\n",
    "    \"contributors\": null,\n",
    "    \"favorite_count\": 228,\n",
    "    \"favorited\": false,\n",
    "    \"in_reply_to_status_id_str\": null,\n",
    "    \"source\": \"<a href=\\\"http://twittbot.net/\\\" rel=\\\"nofollow\\\">twittbot.net</a>\",\n",
    "    \"in_reply_to_user_id\": null,\n",
    "    \"user\": {\n",
    "        \"default_profile\": false,\n",
    "        \"id_str\": \"4017736032\",\n",
    "        \"profile_background_tile\": false,\n",
    "        \"following\": false,\n",
    "        \"description\": \"30+ sec video bot / 30+ 秒 ビデオ bot | Love Live! • Love Live! Sunshine!! • μ's & Aqours seiyuu/声優 | This account no longer accepts requests | ENG only!\",\n",
    "        \"name\": \"30+ sec of ラブライブ!\",\n",
    "        \"profile_sidebar_border_color\": \"000000\",\n",
    "        \"entities\": {\n",
    "            \"description\": {\n",
    "                \"urls\": []\n",
    "            }\n",
    "        },\n",
    "        \"utc_offset\": null,\n",
    "        \"statuses_count\": 2821,\n",
    "        \"notifications\": false,\n",
    "        \"verified\": false,\n",
    "        \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\",\n",
    "        \"profile_image_url\": \"http://pbs.twimg.com/profile_images/751165343968555009/DGbWpedO_normal.jpg\",\n",
    "        \"default_profile_image\": false,\n",
    "        \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/751165343968555009/DGbWpedO_normal.jpg\",\n",
    "        \"geo_enabled\": false,\n",
    "        \"follow_request_sent\": false,\n",
    "        \"is_translation_enabled\": false,\n",
    "        \"profile_use_background_image\": false,\n",
    "        \"protected\": false,\n",
    "        \"favourites_count\": 0,\n",
    "        \"url\": null,\n",
    "        \"followers_count\": 31794,\n",
    "        \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\",\n",
    "        \"profile_link_color\": \"E81C4F\",\n",
    "        \"profile_text_color\": \"000000\",\n",
    "        \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/4017736032/1464317692\",\n",
    "        \"has_extended_profile\": false,\n",
    "        \"is_translator\": false,\n",
    "        \"profile_sidebar_fill_color\": \"000000\",\n",
    "        \"created_at\": \"Sun Oct 25 22:20:47 +0000 2015\",\n",
    "        \"contributors_enabled\": false,\n",
    "        \"friends_count\": 6,\n",
    "        \"id\": 4017736032,\n",
    "        \"profile_background_color\": \"000000\",\n",
    "        \"location\": \"音ノ木坂学院 / 浦の星女学院 \",\n",
    "        \"time_zone\": null,\n",
    "        \"screen_name\": \"30seclovelive\",\n",
    "        \"listed_count\": 228,\n",
    "        \"lang\": \"en\"\n",
    "    },\n",
    "    \"place\": null,\n",
    "    \"geo\": null,\n",
    "    \"truncated\": false,\n",
    "    \"in_reply_to_screen_name\": null,\n",
    "    \"is_quote_status\": false,\n",
    "    \"id\": 758454081656467500,\n",
    "    \"text\": \"movie - hanayo vs. bread #30secLL_bot https://t.co/oQjf1qKsDC\",\n",
    "    \"extended_entities\": {\n",
    "        \"media\": [\n",
    "            {\n",
    "                \"url\": \"https://t.co/oQjf1qKsDC\",\n",
    "                \"id_str\": \"680158074653442048\",\n",
    "                \"source_status_id\": 680158389477875700,\n",
    "                \"source_user_id\": 4017736032,\n",
    "                \"source_user_id_str\": \"4017736032\",\n",
    "                \"media_url_https\": \"https://pbs.twimg.com/ext_tw_video_thumb/680158074653442048/pu/img/UkJ-B_AqbC_vEOcY.jpg\",\n",
    "                \"source_status_id_str\": \"680158389477875712\",\n",
    "                \"sizes\": {\n",
    "                    \"medium\": {\n",
    "                        \"w\": 600,\n",
    "                        \"h\": 338,\n",
    "                        \"resize\": \"fit\"\n",
    "                    },\n",
    "                    \"small\": {\n",
    "                        \"w\": 340,\n",
    "                        \"h\": 191,\n",
    "                        \"resize\": \"fit\"\n",
    "                    },\n",
    "                    \"thumb\": {\n",
    "                        \"w\": 150,\n",
    "                        \"h\": 150,\n",
    "                        \"resize\": \"crop\"\n",
    "                    },\n",
    "                    \"large\": {\n",
    "                        \"w\": 1024,\n",
    "                        \"h\": 576,\n",
    "                        \"resize\": \"fit\"\n",
    "                    }\n",
    "                },\n",
    "                \"display_url\": \"pic.twitter.com/oQjf1qKsDC\",\n",
    "                \"type\": \"video\",\n",
    "                \"id\": 680158074653442000,\n",
    "                \"indices\": [\n",
    "                    38,\n",
    "                    61\n",
    "                ],\n",
    "                \"additional_media_info\": {\n",
    "                    \"monetizable\": false,\n",
    "                    \"source_user\": {\n",
    "                        \"default_profile\": false,\n",
    "                        \"id_str\": \"4017736032\",\n",
    "                        \"profile_background_tile\": false,\n",
    "                        \"following\": false,\n",
    "                        \"description\": \"30+ sec video bot / 30+ 秒 ビデオ bot | Love Live! • Love Live! Sunshine!! • μ's & Aqours seiyuu/声優 | This account no longer accepts requests | ENG only!\",\n",
    "                        \"name\": \"30+ sec of ラブライブ!\",\n",
    "                        \"profile_sidebar_border_color\": \"000000\",\n",
    "                        \"entities\": {\n",
    "                            \"description\": {\n",
    "                                \"urls\": []\n",
    "                            }\n",
    "                        },\n",
    "                        \"utc_offset\": null,\n",
    "                        \"statuses_count\": 2821,\n",
    "                        \"notifications\": false,\n",
    "                        \"verified\": false,\n",
    "                        \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\",\n",
    "                        \"profile_image_url\": \"http://pbs.twimg.com/profile_images/751165343968555009/DGbWpedO_normal.jpg\",\n",
    "                        \"default_profile_image\": false,\n",
    "                        \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/751165343968555009/DGbWpedO_normal.jpg\",\n",
    "                        \"geo_enabled\": false,\n",
    "                        \"follow_request_sent\": false,\n",
    "                        \"is_translation_enabled\": false,\n",
    "                        \"profile_use_background_image\": false,\n",
    "                        \"protected\": false,\n",
    "                        \"favourites_count\": 0,\n",
    "                        \"url\": null,\n",
    "                        \"followers_count\": 31794,\n",
    "                        \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\",\n",
    "                        \"profile_link_color\": \"E81C4F\",\n",
    "                        \"profile_text_color\": \"000000\",\n",
    "                        \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/4017736032/1464317692\",\n",
    "                        \"has_extended_profile\": false,\n",
    "                        \"is_translator\": false,\n",
    "                        \"profile_sidebar_fill_color\": \"000000\",\n",
    "                        \"created_at\": \"Sun Oct 25 22:20:47 +0000 2015\",\n",
    "                        \"contributors_enabled\": false,\n",
    "                        \"friends_count\": 6,\n",
    "                        \"id\": 4017736032,\n",
    "                        \"profile_background_color\": \"000000\",\n",
    "                        \"location\": \"音ノ木坂学院 / 浦の星女学院 \",\n",
    "                        \"time_zone\": null,\n",
    "                        \"screen_name\": \"30seclovelive\",\n",
    "                        \"listed_count\": 228,\n",
    "                        \"lang\": \"en\"\n",
    "                    }\n",
    "                },\n",
    "                \"video_info\": {\n",
    "                    \"duration_millis\": 30000,\n",
    "                    \"variants\": [\n",
    "                        {\n",
    "                            \"url\": \"https://video.twimg.com/ext_tw_video/680158074653442048/pu/pl/yOBp87ckwBL35I8e.m3u8\",\n",
    "                            \"content_type\": \"application/x-mpegURL\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"url\": \"https://video.twimg.com/ext_tw_video/680158074653442048/pu/pl/yOBp87ckwBL35I8e.mpd\",\n",
    "                            \"content_type\": \"application/dash+xml\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"url\": \"https://video.twimg.com/ext_tw_video/680158074653442048/pu/vid/1280x720/cZN0XuT_6u12nwak.mp4\",\n",
    "                            \"content_type\": \"video/mp4\",\n",
    "                            \"bitrate\": 2176000\n",
    "                        },\n",
    "                        {\n",
    "                            \"url\": \"https://video.twimg.com/ext_tw_video/680158074653442048/pu/vid/640x360/-6cs96ywIwtM7-JP.mp4\",\n",
    "                            \"content_type\": \"video/mp4\",\n",
    "                            \"bitrate\": 832000\n",
    "                        },\n",
    "                        {\n",
    "                            \"url\": \"https://video.twimg.com/ext_tw_video/680158074653442048/pu/vid/320x180/Spqi13GJkXZpU_zv.mp4\",\n",
    "                            \"content_type\": \"video/mp4\",\n",
    "                            \"bitrate\": 320000\n",
    "                        }\n",
    "                    ],\n",
    "                    \"aspect_ratio\": [\n",
    "                        16,\n",
    "                        9\n",
    "                    ]\n",
    "                },\n",
    "                \"expanded_url\": \"http://twitter.com/30seclovelive/status/680158389477875712/video/1\",\n",
    "                \"media_url\": \"http://pbs.twimg.com/ext_tw_video_thumb/680158074653442048/pu/img/UkJ-B_AqbC_vEOcY.jpg\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"lang\": \"in\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google APIs is a set of application programming interfaces (APIs) developed by Google which allow communication with Google Services and their integration to other services. Examples of these include Search, Gmail, Translate or Google Maps. Third-party apps can use these APIs to take advantage of or extend the functionality of the existing services.\n",
    "\n",
    "The APIs provide functionality like analytics, machine learning as a service (the Prediction API) or access to user data (when permission to read the data is given). Another important example is an embedded Google map on a website, which can be achieved using the Static maps API,[1] Places API[2] or Google Earth API.[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.jianshu.com/p/d0ffe5f482dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 資料爬蟲--從網站結構撈資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Websites with Python + Beautiful Soup 4 + Requests -- Coding with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"bsp.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from urllib2 import urlopen\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.newegg.com/Product/ProductList.aspx?Submit=ENE&DEPA=0&Order=BESTMATCH&Description=graphics+card&ignorear=0&N=-1&isNodeId=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uClient=urlopen(url)\n",
    "page_html=uClient.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uClient.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_soup=page_soup=soup(page_html,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_soup.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_soup.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_soup.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_soup.body.span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"container.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# div is container need to loop og container to get all div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_soup.body.span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers=page_soup.findAll(\"div\",{\"class\":\"item-container\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(containers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container=containers[0]\n",
    "container.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(container.div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(container.div.div.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(container.div.div.a.img[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "for container in containers:\n",
    "    name=container.div.div.a.img[\"title\"]\n",
    "    brand.append(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container.findAll(\"a\",{'class':\"item-title\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container.findAll(\"a\",{'class':\"item-title\"})[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions=[]\n",
    "for container in containers:\n",
    "    discrib=container.findAll(\"a\",{'class':\"item-title\"})[0].text\n",
    "    descriptions.append(discrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipping_container=container.findAll(\"li\",{'class':\"price-ship\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipping_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipping_container[0].text.strip().split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices=[]\n",
    "for container in containers:\n",
    "    shipping_container=container.findAll(\"li\",{'class':\"price-ship\"})\n",
    "    price=shipping_container[0].text.strip().split(\" \")[0]\n",
    "    prices.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"brand\":brand,\"description\":descriptions,\"price\":prices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.yellowpages.com/search?search_terms=coffee&geo_location_terms=Los+Angeles%2C+CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yp.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from urllib2 import urlopen\n",
    "from bs4 import BeautifulSoup \n",
    "urls=requests.get(\"https://www.yellowpages.com/search?search_terms=coffee&geo_location_terms=Los+Angeles%2C+CA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(urls.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers=soup.findAll(\"div\",{\"class\":\"info\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(containers[0].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(containers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers[0].contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "for item in containers:\n",
    "    name.append(item.contents[0].find_all(\"a\",{\"class\":\"business-name\"})[0].text)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address=[]\n",
    "for item in containers:\n",
    "    address.append(item.contents[1].find_all(\"p\",{'class':\"adr\"})[0].text)\n",
    "    print (item.contents[1].find_all(\"p\",{'class':\"adr\"})[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers[0].contents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers[0].contents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types=[]\n",
    "for item in containers:\n",
    "    types.append(item.contents[2].find_all(\"div\",{'class':\"categories\"})[0].text)\n",
    "    print(item.contents[2].find_all(\"div\",{'class':\"categories\"})[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback=[]\n",
    "for item in containers:\n",
    "    feedback.append(item.contents[4].text)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data={\"name\":name,\"types\":types,\"address\":address,\"feedback\":feedback}\n",
    "df2=pd.DataFrame(data)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/censusgeocode/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import censusgeocode as cg\n",
    "x=cg.onelineaddress('2081 Hillhurst AveLos Angeles, CA 90027')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comma-delimited longitude, latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][\"coordinates\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][\"coordinates\"]['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][\"coordinates\"]['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address=df2['address'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import censusgeocode as cg\n",
    "lat=[]\n",
    "lang=[]\n",
    "for add in address:\n",
    "    try:\n",
    "        x=cg.onelineaddress(add)\n",
    "        lang.append(x[0][\"coordinates\"]['x'])\n",
    "        lat.append(x[0][\"coordinates\"]['y'])\n",
    "    except:\n",
    "        lang.append('NaN')\n",
    "        lat.append('NaN')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"lat\"]=lat\n",
    "df2[\"long\"]=lang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('output.xlsx')\n",
    "df2.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTT 爬文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ptt.cc/cls/7957\n",
    "https://www.ptt.cc/bbs/L_PTTHealth/index2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://carto.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "\n",
    "res = requests.get('https://www.ptt.cc/bbs/Anti-Cancer/search?page='+ \"1\" + '&q=醫院', verify = False)\n",
    "soup = bs(res.text, \"html\")\n",
    "print soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=len('/bbs/Anti-Cancer/M.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "\n",
    "name = []\n",
    "url = []\n",
    "for page in range(1,80):\n",
    "    page = str(page)\n",
    "    res = requests.get('https://www.ptt.cc/bbs/Anti-Cancer/search?page='+ page + '&q=榮總', verify = False)\n",
    "    soup = bs(res.text, \"lxml\")\n",
    "    \n",
    "    # 抓標題    \n",
    "    # 抓網址\n",
    "    for entry in soup.select('.r-ent'):\n",
    "        t1 = soup.find_all('a')\n",
    "        for t2 in t1:\n",
    "            t3 = t2.get('href')\n",
    "            t4 = str(t3)\n",
    "            if t4[:length] == '/bbs/Anti-Cancer/M.':\n",
    "                t5 = 'https://www.ptt.cc'+t4\n",
    "                print(t5)\n",
    "                url.append(t5)\n",
    "                print t2.text\n",
    "                name.append(t2.text)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(name)\n",
    "print len(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "datas={'title':name,'url':url}\n",
    "df=pd.DataFrame(datas)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 記得存檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('ptt_output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "df2 = pd.read_excel('ptt_output.xlsx')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "res = requests.get('https://www.ptt.cc/bbs/Anti-Cancer/M.1550676745.A.31F.html', verify = False)\n",
    "print res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "res = requests.get(df2[\"url\"][0], verify = False)\n",
    "soup = bs(res.text, \"html\")\n",
    "t1 = soup.find_all('div',{\"class\":\"bbs-screen bbs-content\"})\n",
    "print(t1)[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents=[]\n",
    "for url in df2.url.tolist():\n",
    "    \n",
    "    res = requests.get(str(url), verify = False)\n",
    "    soup = bs(res.text, \"lxml\")\n",
    "    t1 = soup.find_all('div',{\"id\":\"main-container\"})\n",
    "    contents.append(t1[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推文的萃取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(df2.url[0], verify = False)\n",
    "soup = bs(res.text, \"lxml\")\n",
    "t1 = soup.find_all('div',{\"class\":\"push\"})\n",
    "print (\"共有幾筆資料:\",len(t1))\n",
    "print (\"==================================================\")\n",
    "push = []\n",
    "for t2 in t1:\n",
    "    t3 = t2.find_all('span',{\"class\":\"f3 push-content\"})\n",
    "    print (t3[0].text[1:])\n",
    "    push.append(t3[0].text[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get all push 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "push=[]\n",
    "for link in df2.url.tolist():\n",
    "    res = requests.get(str(link), verify = False)\n",
    "    soup = bs(res.text, \"lxml\")\n",
    "    t1 = soup.find_all('div',{\"class\":\"push\"})\n",
    "    local_push=[]\n",
    "    for t2 in t1:\n",
    "        t3 = t2.find_all('span',{\"class\":\"f3 push-content\"})\n",
    "        local_push.append(t3[0].text[1:])\n",
    "         \n",
    "    text=\" \".join(local_push)\n",
    "    push.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(push)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 儲存content and push 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"content\"]=contents\n",
    "df2[\"push\"]=push\n",
    "df2.to_excel('ptt_content.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
